# ğŸ•µï¸â€â™‚ï¸ Uncover-LLMs  
ğŸš€ A lightweight LLM-powered app to **interact with text** using local & private AI models.  

[Watch Demo Video](http://www.uncover-llms.com/)


## âœ¨ Features  
âœ… Use **Llama3.2, DeepSeek, or other models offline**  
âœ… Query AI without an internet connection  
âœ… **Private & Secure** â€“ No data sent to external servers  
âœ… **Fast & Lightweight** â€“ Runs on local machines  

---

## ğŸ› ï¸ **Installation & Setup**  

### 1ï¸âƒ£ **Download & Install Ollama**  
Ollama is required to run LLMs offline. Install it from:  
ğŸ”— [https://ollama.com](https://ollama.com)  

MacOS (Homebrew):  
```sh  
brew install ollama  
```
Linux:  
```sh  
curl -fsSL https://ollama.com/install.sh | sh  
```
Windows:  
ğŸ“Œ Download the [Windows Installer](https://ollama.com/download).  

---

### 2ï¸âƒ£ **Download a Local Model**  
After installing Ollama, pull a model:  

#### **Option 1: DeepSeek (Faster & Efficient)**  
```sh  
ollama pull deepseek:latest  
```

#### **Option 2: LLaMA3 (Metaâ€™s AI Model)**  
```sh  
ollama pull llama3  
```

#### **Option 3: Mistral (Lightweight Alternative)**  
```sh  
ollama pull mistral  
```

---

### 3ï¸âƒ£ **Clone & Run Uncover-LLMs**  
```sh  
git clone https://github.com/your-username/Uncover-LLMs.git  
cd Uncover-LLMs  
pip install -r requirements.txt  
python app.py  
```
Now open your **browser** and access:  
ğŸ“Œ **http://127.0.0.1:5000**  

---

## ğŸš§ **Current Version Limitations**  
ğŸš¨ **This version supports only plain text input** â€“ No PDF/Excel file support yet!  

---

## ğŸ¤ **Contributing**  
We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for details.  

## ğŸ“œ **License**  
MIT License â€“ Free to use & modify.  

---

ğŸš€ **Enjoy using Uncover-LLMs?** Give it a â­ on GitHub!  

