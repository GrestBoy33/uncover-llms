# 🕵️‍♂️ Uncover-LLMs  
🚀 A lightweight LLM-powered app to **interact with text** using local & private AI models.  

[Watch Demo Video](http://www.uncover-llms.com/)


## ✨ Features  
✅ Use **Llama3.2, DeepSeek, or other models offline**  
✅ Query AI without an internet connection  
✅ **Private & Secure** – No data sent to external servers  
✅ **Fast & Lightweight** – Runs on local machines  

---

## 🛠️ **Installation & Setup**  

### 1️⃣ **Download & Install Ollama**  
Ollama is required to run LLMs offline. Install it from:  
🔗 [https://ollama.com](https://ollama.com)  

MacOS (Homebrew):  
```sh  
brew install ollama  
```
Linux:  
```sh  
curl -fsSL https://ollama.com/install.sh | sh  
```
Windows:  
📌 Download the [Windows Installer](https://ollama.com/download).  

---

### 2️⃣ **Download a Local Model**  
After installing Ollama, pull a model:  

#### **Option 1: DeepSeek (Faster & Efficient)**  
```sh  
ollama pull deepseek:latest  
```

#### **Option 2: LLaMA3 (Meta’s AI Model)**  
```sh  
ollama pull llama3  
```

#### **Option 3: Mistral (Lightweight Alternative)**  
```sh  
ollama pull mistral  
```

---

### 3️⃣ **Clone & Run Uncover-LLMs**  
```sh  
git clone https://github.com/your-username/Uncover-LLMs.git  
cd Uncover-LLMs  
pip install -r requirements.txt  
python app.py  
```
Now open your **browser** and access:  
📌 **http://127.0.0.1:5000**  

---

## 🚧 **Current Version Limitations**  
🚨 **This version supports only plain text input** – No PDF/Excel file support yet!  

---

## 🤝 **Contributing**  
We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for details.  

## 📜 **License**  
MIT License – Free to use & modify.  

---

🚀 **Enjoy using Uncover-LLMs?** Give it a ⭐ on GitHub!  

